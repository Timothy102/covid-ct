{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thick-discovery",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import cv\n",
    "import torch\n",
    "import cv2\n",
    "from cv2 import resize\n",
    "import nrrd\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "steady-night",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = (192, 192, 3)\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "valratio = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aquatic-sight",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'HACKATHON/images/train/'\n",
    "test_path = 'HACKATHON/images/test/'\n",
    "label_path = 'HACKATHON/train.txt'\n",
    "segmentation_path = 'HACKATHON/segmentations/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "architectural-yugoslavia",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = []\n",
    "with open(label_path, 'r') as f:\n",
    "    for row in f:\n",
    "        ss.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rotary-collaboration",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(os.listdir(train_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorrect-roots",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadnib(path, root = train_path):\n",
    "    scan = nib.load(root+ path)\n",
    "    return np.array(scan.dataobj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "featured-driving",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = loadnib('0657.nii.gz')\n",
    "img.shape, img[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "textile-envelope",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nibtoimg(path, root = train_path, slc = 25, file = 't.jpg'):\n",
    "    scan = nib.load(root+ path)\n",
    "    scan = np.array(scan.dataobj)\n",
    "    t = np.rot90(scan[:,:,slc], k=3)\n",
    "    plt.imsave(file, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "local-devices",
   "metadata": {},
   "outputs": [],
   "source": [
    "nibtoimg('0013.nii.gz',root = test_path, slc = 72, file = 'curr.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utility-currency",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = rgb_loader('curr.jpg')\n",
    "plt.imshow(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colonial-trail",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_slice(img, slc):\n",
    "    plt.imshow(np.rot90(img[:,:,slc], k=3),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educated-comfort",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_slice(img, 34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specific-flood",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporate-national",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for k in sorted(ss):\n",
    "    a,b = k.split(',')\n",
    "    labels.append(int(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "above-fairy",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(labels)\n",
    "labels = np.expand_dims(labels, axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooperative-fossil",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_img(img, path = 'output.jpeg'):\n",
    "    plt.imsave(path, img, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "typical-watershed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "def rgb_loader(path):\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.resize(img, (352, 352))\n",
    "    return Image.fromarray(img)\n",
    "\n",
    "\n",
    "def transform(x):\n",
    "    operation = transforms.Compose([\n",
    "                transforms.Resize((352, 352)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                    [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    return operation(x).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "buried-stretch",
   "metadata": {},
   "outputs": [],
   "source": [
    "k  = rgb_loader('t.jpg')\n",
    "plt.imshow(k, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earned-rebel",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ready(n, slc = 0):\n",
    "    im = Image.fromarray(n[:,:,slc])\n",
    "    im = im.convert('RGB')\n",
    "    return transform(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "native-paint",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = get_ready(k)\n",
    "plt.imshow(k[:,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collect-diesel",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen(path = train_path):\n",
    "    for filepath in os.listdir(path):\n",
    "        try:\n",
    "            scan = nib.load(path+filepath)\n",
    "            yield np.array(scan.dataobj)\n",
    "        except StopIteration:\n",
    "            break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ideal-vaccine",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "urban-theology",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = next(g)\n",
    "n = n.astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "korean-stack",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.rot90(n[:,:,23], k = 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noble-pierce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"You mothafucka\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "athletic-phase",
   "metadata": {},
   "source": [
    "## Semi Inf-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "national-virtue",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p Results/semi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "representative-holly",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'Results/semi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governing-intensity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "__all__ = ['Res2Net', 'res2net50_v1b', 'res2net101_v1b', 'res2net50_v1b_26w_4s']\n",
    "\n",
    "model_urls = {\n",
    "    'res2net50_v1b_26w_4s': 'https://shanghuagao.oss-cn-beijing.aliyuncs.com/res2net/res2net50_v1b_26w_4s-3cf99910.pth',\n",
    "    'res2net101_v1b_26w_4s': 'https://shanghuagao.oss-cn-beijing.aliyuncs.com/res2net/res2net101_v1b_26w_4s-0812c246.pth',\n",
    "}\n",
    "\n",
    "\n",
    "class Bottle2neck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, baseWidth=26, scale=4, stype='normal'):\n",
    "        \"\"\" Constructor\n",
    "        Args:\n",
    "            inplanes: input channel dimensionality\n",
    "            planes: output channel dimensionality\n",
    "            stride: conv stride. Replaces pooling layer.\n",
    "            downsample: None when stride = 1\n",
    "            baseWidth: basic width of conv3x3\n",
    "            scale: number of scale.\n",
    "            type: 'normal': normal set. 'stage': first block of a new stage.\n",
    "        \"\"\"\n",
    "        super(Bottle2neck, self).__init__()\n",
    "\n",
    "        width = int(math.floor(planes * (baseWidth / 64.0)))\n",
    "        self.conv1 = nn.Conv2d(inplanes, width * scale, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(width * scale)\n",
    "\n",
    "        if scale == 1:\n",
    "            self.nums = 1\n",
    "        else:\n",
    "            self.nums = scale - 1\n",
    "        if stype == 'stage':\n",
    "            self.pool = nn.AvgPool2d(kernel_size=3, stride=stride, padding=1)\n",
    "        convs = []\n",
    "        bns = []\n",
    "        for i in range(self.nums):\n",
    "            convs.append(nn.Conv2d(width, width, kernel_size=3, stride=stride, padding=1, bias=False))\n",
    "            bns.append(nn.BatchNorm2d(width))\n",
    "        self.convs = nn.ModuleList(convs)\n",
    "        self.bns = nn.ModuleList(bns)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(width * scale, planes * self.expansion, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stype = stype\n",
    "        self.scale = scale\n",
    "        self.width = width\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        spx = torch.split(out, self.width, 1)\n",
    "        for i in range(self.nums):\n",
    "            if i == 0 or self.stype == 'stage':\n",
    "                sp = spx[i]\n",
    "            else:\n",
    "                sp = sp + spx[i]\n",
    "            sp = self.convs[i](sp)\n",
    "            sp = self.relu(self.bns[i](sp))\n",
    "            if i == 0:\n",
    "                out = sp\n",
    "            else:\n",
    "                out = torch.cat((out, sp), 1)\n",
    "        if self.scale != 1 and self.stype == 'normal':\n",
    "            out = torch.cat((out, spx[self.nums]), 1)\n",
    "        elif self.scale != 1 and self.stype == 'stage':\n",
    "            out = torch.cat((out, self.pool(spx[self.nums])), 1)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Res2Net(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, baseWidth=26, scale=4, num_classes=1000):\n",
    "        self.inplanes = 64\n",
    "        super(Res2Net, self).__init__()\n",
    "        self.baseWidth = baseWidth\n",
    "        self.scale = scale\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 64, 3, 1, 1, bias=False)\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.AvgPool2d(kernel_size=stride, stride=stride,\n",
    "                             ceil_mode=True, count_include_pad=False),\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=1, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample=downsample,\n",
    "                            stype='stage', baseWidth=self.baseWidth, scale=self.scale))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, baseWidth=self.baseWidth, scale=self.scale))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def res2net50_v1b(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a Res2Net-50_v1b model_lung_infection.\n",
    "    Res2Net-50 refers to the Res2Net-50_v1b_26w_4s.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model_lung_infection pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = Res2Net(Bottle2neck, [3, 4, 6, 3], baseWidth=26, scale=4, **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['res2net50_v1b_26w_4s']),map_location=torch.device('cpu') )\n",
    "    return model\n",
    "\n",
    "\n",
    "def res2net101_v1b(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a Res2Net-50_v1b_26w_4s model_lung_infection.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model_lung_infection pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = Res2Net(Bottle2neck, [3, 4, 23, 3], baseWidth=26, scale=4, **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['res2net101_v1b_26w_4s']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def res2net50_v1b_26w_4s(pretrained=True, **kwargs):\n",
    "    \"\"\"Constructs a Res2Net-50_v1b_26w_4s model_lung_infection.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model_lung_infection pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = Res2Net(Bottle2neck, [3, 4, 6, 3], baseWidth=26, scale=4, **kwargs)\n",
    "    if pretrained:\n",
    "        # Please replace it with your custom path\n",
    "        model_state = torch.load('res2net50_v1b_26w_4s-3cf99910.pth', map_location=torch.device('cpu'))\n",
    "        model.load_state_dict(model_state)\n",
    "        # model_lung_infection.load_state_dict(model_zoo.load_url(model_urls['res2net50_v1b_26w_4s']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def res2net101_v1b_26w_4s(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a Res2Net-50_v1b_26w_4s model_lung_infection.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model_lung_infection pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = Res2Net(Bottle2neck, [3, 4, 23, 3], baseWidth=26, scale=4, **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['res2net101_v1b_26w_4s']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def res2net152_v1b_26w_4s(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a Res2Net-50_v1b_26w_4s model_lung_infection.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model_lung_infection pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = Res2Net(Bottle2neck, [3, 8, 36, 3], baseWidth=26, scale=4, **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['res2net152_v1b_26w_4s']))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eastern-demonstration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class BasicConv2d(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, kernel_size, stride=1, padding=0, dilation=1):\n",
    "        super(BasicConv2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_planes, out_planes,\n",
    "                              kernel_size=kernel_size, stride=stride,\n",
    "                              padding=padding, dilation=dilation, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(out_planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class RFB_modified(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        super(RFB_modified, self).__init__()\n",
    "        self.relu = nn.ReLU(True)\n",
    "        self.branch0 = nn.Sequential(\n",
    "            BasicConv2d(in_channel, out_channel, 1),\n",
    "        )\n",
    "        self.branch1 = nn.Sequential(\n",
    "            BasicConv2d(in_channel, out_channel, 1),\n",
    "            BasicConv2d(out_channel, out_channel, kernel_size=(1, 3), padding=(0, 1)),\n",
    "            BasicConv2d(out_channel, out_channel, kernel_size=(3, 1), padding=(1, 0)),\n",
    "            BasicConv2d(out_channel, out_channel, 3, padding=3, dilation=3)\n",
    "        )\n",
    "        self.branch2 = nn.Sequential(\n",
    "            BasicConv2d(in_channel, out_channel, 1),\n",
    "            BasicConv2d(out_channel, out_channel, kernel_size=(1, 5), padding=(0, 2)),\n",
    "            BasicConv2d(out_channel, out_channel, kernel_size=(5, 1), padding=(2, 0)),\n",
    "            BasicConv2d(out_channel, out_channel, 3, padding=5, dilation=5)\n",
    "        )\n",
    "        self.branch3 = nn.Sequential(\n",
    "            BasicConv2d(in_channel, out_channel, 1),\n",
    "            BasicConv2d(out_channel, out_channel, kernel_size=(1, 7), padding=(0, 3)),\n",
    "            BasicConv2d(out_channel, out_channel, kernel_size=(7, 1), padding=(3, 0)),\n",
    "            BasicConv2d(out_channel, out_channel, 3, padding=7, dilation=7)\n",
    "        )\n",
    "        self.conv_cat = BasicConv2d(4*out_channel, out_channel, 3, padding=1)\n",
    "        self.conv_res = BasicConv2d(in_channel, out_channel, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.branch0(x)\n",
    "        x1 = self.branch1(x)\n",
    "        x2 = self.branch2(x)\n",
    "        x3 = self.branch3(x)\n",
    "        x_cat = self.conv_cat(torch.cat((x0, x1, x2, x3), 1))\n",
    "\n",
    "        x = self.relu(x_cat + self.conv_res(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "class aggregation(nn.Module):\n",
    "    # dense aggregation, it can be replaced by other aggregation previous, such as DSS, amulet, and so on.\n",
    "    # used after MSF\n",
    "    def __init__(self, channel, n_class):\n",
    "        super(aggregation, self).__init__()\n",
    "        self.relu = nn.ReLU(True)\n",
    "\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.conv_upsample1 = BasicConv2d(channel, channel, 3, padding=1)\n",
    "        self.conv_upsample2 = BasicConv2d(channel, channel, 3, padding=1)\n",
    "        self.conv_upsample3 = BasicConv2d(channel, channel, 3, padding=1)\n",
    "        self.conv_upsample4 = BasicConv2d(channel, channel, 3, padding=1)\n",
    "        self.conv_upsample5 = BasicConv2d(2*channel, 2*channel, 3, padding=1)\n",
    "\n",
    "        self.conv_concat2 = BasicConv2d(2*channel, 2*channel, 3, padding=1)\n",
    "        self.conv_concat3 = BasicConv2d(3*channel, 3*channel, 3, padding=1)\n",
    "        self.conv4 = BasicConv2d(3*channel, 3*channel, 3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(3*channel, n_class, 1)\n",
    "\n",
    "    def forward(self, x1, x2, x3):\n",
    "        x1_1 = x1\n",
    "        x2_1 = self.conv_upsample1(self.upsample(x1)) * x2\n",
    "        x3_1 = self.conv_upsample2(self.upsample(self.upsample(x1))) \\\n",
    "               * self.conv_upsample3(self.upsample(x2)) * x3\n",
    "\n",
    "        x2_2 = torch.cat((x2_1, self.conv_upsample4(self.upsample(x1_1))), 1)\n",
    "        x2_2 = self.conv_concat2(x2_2)\n",
    "\n",
    "        x3_2 = torch.cat((x3_1, self.conv_upsample5(self.upsample(x2_2))), 1)\n",
    "        x3_2 = self.conv_concat3(x3_2)\n",
    "\n",
    "        x = self.conv4(x3_2)\n",
    "        x = self.conv5(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Inf_Net(nn.Module):\n",
    "    def __init__(self, channel=32, n_class=1):\n",
    "        super(Inf_Net, self).__init__()\n",
    "        # ---- ResNet Backbone ----\n",
    "        self.resnet = res2net50_v1b_26w_4s(pretrained=True)\n",
    "        # ---- Receptive Field Block like module ----\n",
    "        self.rfb2_1 = RFB_modified(512, channel)\n",
    "        self.rfb3_1 = RFB_modified(1024, channel)\n",
    "        self.rfb4_1 = RFB_modified(2048, channel)\n",
    "\n",
    "        # ---- Partial Decoder ----\n",
    "        self.ParDec = aggregation(channel, n_class)\n",
    "\n",
    "        # ---- reverse attention branch 4 ----\n",
    "        self.ra4_conv1 = BasicConv2d(2048, 256, kernel_size=1)\n",
    "        self.ra4_conv2 = BasicConv2d(256+64, 256, kernel_size=5, padding=2)\n",
    "        self.ra4_conv3 = BasicConv2d(256, 256, kernel_size=5, padding=2)\n",
    "        self.ra4_conv4 = BasicConv2d(256, 256, kernel_size=5, padding=2)\n",
    "        self.ra4_conv5 = BasicConv2d(256, n_class, kernel_size=1)\n",
    "        # ---- reverse attention branch 3 ----\n",
    "        self.ra3_conv1 = BasicConv2d(1024, 64, kernel_size=1)\n",
    "        self.ra3_conv2 = BasicConv2d(64+64, 64, kernel_size=3, padding=1)\n",
    "        self.ra3_conv3 = BasicConv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.ra3_conv4 = BasicConv2d(64, n_class, kernel_size=3, padding=1)\n",
    "        # ---- reverse attention branch 2 ----\n",
    "        self.ra2_conv1 = BasicConv2d(512, 64, kernel_size=1)\n",
    "        self.ra2_conv2 = BasicConv2d(64+64, 64, kernel_size=3, padding=1)\n",
    "        self.ra2_conv3 = BasicConv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.ra2_conv4 = BasicConv2d(64, n_class, kernel_size=3, padding=1)\n",
    "\n",
    "        # ---- edge branch ----\n",
    "        self.edge_conv1 = BasicConv2d(256, 64, kernel_size=1)\n",
    "        self.edge_conv2 = BasicConv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.edge_conv3 = BasicConv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.edge_conv4 = BasicConv2d(64, n_class, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet.conv1(x)\n",
    "        x = self.resnet.bn1(x)\n",
    "        x = self.resnet.relu(x)\n",
    "\n",
    "        # ---- low-level features ----\n",
    "        x = self.resnet.maxpool(x)      # bs, 64, 88, 88\n",
    "        x1 = self.resnet.layer1(x)      # bs, 256, 88, 88\n",
    "\n",
    "        # ---- high-level features ----\n",
    "        x2 = self.resnet.layer2(x1)     # bs, 512, 44, 44\n",
    "        x3 = self.resnet.layer3(x2)     # bs, 1024, 22, 22\n",
    "        x4 = self.resnet.layer4(x3)     # bs, 2048, 11, 11\n",
    "        x2_rfb = self.rfb2_1(x2)        # channel -> 32\n",
    "        x3_rfb = self.rfb3_1(x3)        # channel -> 32\n",
    "        x4_rfb = self.rfb4_1(x4)        # channel -> 32\n",
    "\n",
    "        # ---- edge guidance ----\n",
    "        x = self.edge_conv1(x1)\n",
    "        x = self.edge_conv2(x)\n",
    "        edge_guidance = self.edge_conv3(x)  # torch.Size([1, 64, 88, 88])\n",
    "        lateral_edge = self.edge_conv4(edge_guidance)   # NOTES: Sup-2 (bs, 1, 88, 88) -> (bs, 1, 352, 352)\n",
    "        lateral_edge = F.interpolate(lateral_edge,\n",
    "                                     scale_factor=4,\n",
    "                                     mode='bilinear')\n",
    "\n",
    "        # ---- global guidance ----\n",
    "        ra5_feat = self.ParDec(x4_rfb, x3_rfb, x2_rfb)\n",
    "        lateral_map_5 = F.interpolate(ra5_feat,\n",
    "                                      scale_factor=8,\n",
    "                                      mode='bilinear')    # NOTES: Sup-1 (bs, 1, 44, 44) -> (bs, 1, 352, 352)\n",
    "\n",
    "        # ---- reverse attention branch_4 ----\n",
    "        crop_4 = F.interpolate(ra5_feat, scale_factor=0.25, mode='bilinear')\n",
    "        x = -1*(torch.sigmoid(crop_4)) + 1  # reverse\n",
    "        x = x.expand(-1, 2048, -1, -1).mul(x4)\n",
    "        x = torch.cat((self.ra4_conv1(x), F.interpolate(edge_guidance, scale_factor=1/8, mode='bilinear')), dim=1)\n",
    "        x = F.relu(self.ra4_conv2(x))\n",
    "        x = F.relu(self.ra4_conv3(x))\n",
    "        x = F.relu(self.ra4_conv4(x))\n",
    "        ra4_feat = self.ra4_conv5(x)\n",
    "        x = ra4_feat + crop_4   # element-wise addition\n",
    "        lateral_map_4 = F.interpolate(x,\n",
    "                                      scale_factor=32,\n",
    "                                      mode='bilinear')  # NOTES: Sup-2 (bs, 1, 11, 11) -> (bs, 1, 352, 352)\n",
    "\n",
    "        # ---- reverse attention branch_3 ----\n",
    "        crop_3 = F.interpolate(x, scale_factor=2, mode='bilinear')\n",
    "        x = -1*(torch.sigmoid(crop_3)) + 1\n",
    "        x = x.expand(-1, 1024, -1, -1).mul(x3)\n",
    "        x = torch.cat((self.ra3_conv1(x), F.interpolate(edge_guidance, scale_factor=1/4, mode='bilinear')), dim=1)\n",
    "        x = F.relu(self.ra3_conv2(x))\n",
    "        x = F.relu(self.ra3_conv3(x))\n",
    "        ra3_feat = self.ra3_conv4(x)\n",
    "        x = ra3_feat + crop_3\n",
    "        lateral_map_3 = F.interpolate(x,\n",
    "                                      scale_factor=16,\n",
    "                                      mode='bilinear')  # NOTES: Sup-3 (bs, 1, 22, 22) -> (bs, 1, 352, 352)\n",
    "\n",
    "        # ---- reverse attention branch_2 ----\n",
    "        crop_2 = F.interpolate(x, scale_factor=2, mode='bilinear')\n",
    "\n",
    "        x = -1*(torch.sigmoid(crop_2)) + 1\n",
    "        x = x.expand(-1, 512, -1, -1).mul(x2)\n",
    "        x = torch.cat((self.ra2_conv1(x), F.interpolate(edge_guidance, scale_factor=1/2, mode='bilinear')), dim=1)\n",
    "        x = F.relu(self.ra2_conv2(x))\n",
    "        x = F.relu(self.ra2_conv3(x))\n",
    "        ra2_feat = self.ra2_conv4(x)\n",
    "        x = ra2_feat + crop_2\n",
    "        lateral_map_2 = F.interpolate(x,\n",
    "                                      scale_factor=8,\n",
    "                                      mode='bilinear')   # NOTES: Sup-4 (bs, 1, 44, 44) -> (bs, 1, 352, 352)\n",
    "\n",
    "        return lateral_map_5, lateral_map_4, lateral_map_3, lateral_map_2, lateral_edge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heard-looking",
   "metadata": {},
   "outputs": [],
   "source": [
    "seminet_pth ='Semi-Inf-Net/Semi-Inf-Net-100.pth'\n",
    "save_test = 'Results/Lung-infection-segmentation/Semi-Inf-Net/'\n",
    "save_train = 'Results/Lung-infection-segmentation/train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equivalent-lightning",
   "metadata": {},
   "outputs": [],
   "source": [
    "semi = Inf_Net()\n",
    "device = torch.device('cpu')\n",
    "semi.load_state_dict(torch.load(seminet_pth, map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generous-pitch",
   "metadata": {},
   "outputs": [],
   "source": [
    "semi.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expanded-baltimore",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_semi(k):\n",
    "    lateral_map_5, lateral_map_4, lateral_map_3, lateral_map_2, lateral_edge = semi(k)\n",
    "    res = lateral_map_2\n",
    "    res = res.sigmoid().data.cpu().numpy().squeeze()\n",
    "    res = (res - res.min()) / (res.max() - res.min() + 1e-8)\n",
    "    #plt.imsave(save_path + '0.jpeg' ,res, cmap = 'gray')\n",
    "    #plt.imshow(res, cmap='gray')\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dress-roads",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = next(g)\n",
    "plot_slice(n, slc = 34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lined-bradley",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = get_ready(n)\n",
    "x = predict_semi(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adult-tokyo",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.rot90(x), cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "everyday-payday",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_lungs_slice(filepath_mask, slice_number):\n",
    "    M, _ = nrrd.read(filepath_mask)\n",
    "    current_slice, _ = bound_box_and_reshape(M, slice_number)\n",
    "    num_pixels = current_slice.shape[2] * current_slice.shape[1]\n",
    "    white = np.sum(current_slice)\n",
    "    return \"{:.1f}\".format(white / num_pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superb-business",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bound_box_and_reshape(img, slice_idx):\n",
    "    \"\"\"\n",
    "    Crop given slice of image to lung size (remove redundant empty space) and reshape to 512x512 pxls. Return edited img_slice.\n",
    "    \"\"\"\n",
    "    img_slice = img[:,:,slice_idx]    \n",
    "    rows = np.any(img_slice, axis=1)\n",
    "    cols = np.any(img_slice, axis=0)\n",
    "    rmin, rmax = np.where(rows)[0][[0, -1]]\n",
    "    cmin, cmax = np.where(cols)[0][[0, -1]]\n",
    "    img_slice = resize(img_slice[rmin:rmax, cmin:cmax], (512,512))\n",
    "    img_slice = np.transpose(img_slice[:, :, np.newaxis], axes = [2, 0, 1]).astype('float32')\n",
    "    lung_pixels = abs((rmax-rmin) * (cmax - cmin))\n",
    "    \n",
    "    return img_slice, lung_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dying-enterprise",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_original(filepath_CT, filepath_mask):\n",
    "    \"\"\"\n",
    "    Mask and normalize original CT. Select only preset number of central slices. \n",
    "    \"\"\"\n",
    "    I = np.array(nib.load(filepath_CT).dataobj)\n",
    "    #I = normalize(I, -1350, 150)\n",
    "    M, _ = nrrd.read(filepath_mask)\n",
    "    \n",
    "    nS = np.where(M==1, I, M)\n",
    "    \n",
    "    #z = nS.shape[2]//2\n",
    "    #dz = nb_central_slices//2\n",
    "    #nS = nS[:,:,z-dz:z+dz]\n",
    "        \n",
    "    return nS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "published-large",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_img = '0013.nii.gz'\n",
    "i = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "original-breakdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_mask = filename_img.replace(\".nii.gz\", \".nrrd\")\n",
    "filepath_img = os.path.join(test_path, filename_img)\n",
    "filepath_mask = os.path.join(segmentation_path+\"test/\", filename_mask)\n",
    "patient_number = filename_mask.split(\".nrrd\")[0]\n",
    "img = mask_original(filepath_img, filepath_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "devoted-poison",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(img[:,:,45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "orange-edgar",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_slice, bbox_pixels = bound_box_and_reshape(img, i)\n",
    "current_slice = np.rot90(np.squeeze(current_slice))\n",
    "percentage = percent_lungs_slice(filepath_mask, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-minimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(current_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reasonable-union",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imsave('cur.jpg', current_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transsexual-playback",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = transform(rgb_loader('cur.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "academic-vacation",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = predict_semi(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honey-principle",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(r)\n",
    "plt.imsave('semi.jpg', r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statewide-norfolk",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Image.fromarray(current_slice).convert('RGB')\n",
    "x = transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valued-withdrawal",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = predict_semi(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "printable-residence",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innovative-grant",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = transform(rgb_loader('semi.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "through-preservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sudden-monaco",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_results(path = test_path):\n",
    "    for k in tqdm(os.listdir(path)):\n",
    "        save_pseudo(k, opt = save_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stupid-university",
   "metadata": {},
   "outputs": [],
   "source": [
    "#store_results(path = train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baking-miniature",
   "metadata": {},
   "outputs": [],
   "source": [
    "saving_path = 'Results/wash/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aquatic-pixel",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mask_area_percentage(mask, NP_VALUE_OF_MASK):\n",
    "    \"\"\"\n",
    "        Input je numpy array. Vrže ven odstotek, kolikšen\n",
    "        del slike zajema anomalija.\n",
    "    \"\"\"\n",
    "    mask = np.where(mask == NP_VALUE_OF_MASK, 1, 0)\n",
    "    summa = np.sum(mask)\n",
    "    percentage = float(summa) / (mask.shape[0]*mask.shape[1])\n",
    "    return round(percentage,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparable-interval",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_slice(slice_image, slice_name):\n",
    "    plt.imsave(os.path.join(saving_path, slice_name + \".jpg\"), np.rot90(np.squeeze(slice_image), k=3),cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "little-education",
   "metadata": {},
   "source": [
    "# Semi Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mexican-punishment",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Semi-Inf-Net_UNet/unet_model_200.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-narrative",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels , in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        # if you have padding issues, see\n",
    "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
    "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustained-algorithm",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inf_Net_UNet(nn.Module):\n",
    "    \"\"\" Full assembly of the parts to form the complete network \"\"\"\n",
    "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
    "        super(Inf_Net_UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = Down(512, 1024 // factor)\n",
    "        self.up1 = Up(1024, 512 // factor, bilinear)\n",
    "        self.up2 = Up(512, 256 // factor, bilinear)\n",
    "        self.up3 = Up(256, 128 // factor, bilinear)\n",
    "        self.up4 = Up(128, 64, bilinear)\n",
    "        self.outc = OutConv(64, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriental-trader",
   "metadata": {},
   "outputs": [],
   "source": [
    "infnet = Inf_Net_UNet(6,3)\n",
    "device = torch.device('cpu')\n",
    "infnet.load_state_dict(torch.load(path, map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-exclusive",
   "metadata": {},
   "outputs": [],
   "source": [
    "infnet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manual-sandwich",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imsave('pseudo.jpeg', k.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nominated-delivery",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_unet(k,d):\n",
    "    s = torch.cat((k,d), dim=1)\n",
    "    res = infnet(s)\n",
    "    res = torch.sigmoid(res) \n",
    "    b, _, w, h = res.size()\n",
    "    # output b*n_class*h*w -- > b*h*w\n",
    "    pred = res.cpu().permute(0, 2, 3, 1).contiguous().view(-1, 3).max(1)[1].view(b, w, h).numpy().squeeze()\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "starting-hurricane",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_class_imgs(pred):\n",
    "    im_array_red = np.array(pred)  # 0, 38\n",
    "    im_array_green = np.array(pred)  # 0, 75\n",
    "    print(np.unique(im_array_red)) # mask value is max of this\n",
    "\n",
    "    im_array_red[im_array_red != 0] = 1\n",
    "    im_array_red[im_array_red == 0] = 255\n",
    "    im_array_red[im_array_red == 1] = 0\n",
    "\n",
    "    im_array_green[im_array_green != 1] = 0\n",
    "    im_array_green[im_array_green == 1] = 255\n",
    "    \n",
    "   # red = Image.fromarray(im_array_red).convert('1').resize(size=(512, 512))\n",
    "    #green = Image.fromarray(im_array_red).convert('1').resize(size=(512, 512))\n",
    "\n",
    "    return im_array_green, im_array_red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monthly-jumping",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_PATH = 'HACKATHON/train.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "killing-leadership",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(patient_number):\n",
    "    with open(LABEL_PATH) as file:\n",
    "        for line in file.readlines():\n",
    "            if str(patient_number) in line:\n",
    "                label = line.split(\",\")[1].rsplit(\"\\n\")[0]\n",
    "                return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indonesian-governor",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  končna segmentacija(summa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-clerk",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_one_patient(filename_img, path = train_path, seg_path = segmentation_path):\n",
    "    filename_mask = filename_img.replace(\".nii.gz\", \".nrrd\")\n",
    "    filepath_img = os.path.join(path, filename_img)\n",
    "    filepath_mask = os.path.join(seg_path, filename_mask)\n",
    "    patient_number = filename_mask.split(\".nrrd\")[0]\n",
    "    img = mask_original(filepath_img, filepath_mask)\n",
    "    num_slices = img.shape[2]\n",
    "    \n",
    "    label = get_label(patient_number)\n",
    "    \n",
    "    patient_lung_volume_score = 0.0\n",
    "    patient_ggo_score = 0.0\n",
    "    patient_consolidation_score = 0.0\n",
    "        \n",
    "    for i in tqdm(range(num_slices)):\n",
    "        try:\n",
    "            current_slice, bbox_pixels = bound_box_and_reshape(img, i)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "        current_slice = np.rot90(np.squeeze(current_slice))\n",
    "        percentage = percent_lungs_slice(filepath_mask, i)\n",
    "        if percentage != 0:\n",
    "            plt.imsave('cur.png', current_slice)\n",
    "            t = transform(rgb_loader('cur.png'))\n",
    "            r = predict_semi(t)\n",
    "            plt.imsave('semi.png', r)\n",
    "            e = transform(rgb_loader('semi.png'))\n",
    "            pred = predict_unet(t,e)\n",
    "            ggo_mask, consolidation_mask = split_class_imgs(pred)\n",
    "            \n",
    "            NP_VALUE_OF_MASK = 255\n",
    "            patient_lung_volume_score += float(percentage) * bbox_pixels\n",
    "            \n",
    "            ggo_percentage = calculate_mask_area_percentage(ggo_mask, NP_VALUE_OF_MASK)\n",
    "            consolidation_percentage = calculate_mask_area_percentage(consolidation_mask, NP_VALUE_OF_MASK)\n",
    "            \n",
    "            patient_ggo_score += ggo_percentage * bbox_pixels\n",
    "            patient_consolidation_score += consolidation_percentage * bbox_pixels\n",
    "            \n",
    "            plt.show()\n",
    "    \n",
    "    return {\"filename_img\" : filename_img,\n",
    "            \"label\" : label,\n",
    "            \"lung_vol\": patient_lung_volume_score, \n",
    "            \"ggo_vol\" : patient_ggo_score, \n",
    "            \"cons_vol\" : patient_consolidation_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "studied-mentor",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = os.listdir(train_path)[:30]\n",
    "training_csv = 'proba.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earlier-incident",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reliable-dancing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_patients(path = bet_path, seg_path = seg_p):\n",
    "    training_set = []\n",
    "    for _,_,filenames in os.walk(path):\n",
    "        for filename in tqdm(filenames):\n",
    "            if filename.endswith(\".nii.gz\"):\n",
    "                patient_dict = process_one_patient(filename, path = path, seg_path = seg_path)\n",
    "                with open(training_csv, mode='a') as file_:\n",
    "                    file_.write(str(patient_dict.values()))\n",
    "                    file_.write(\"\\n\")\n",
    "                training_set.append(patient_dict)\n",
    "    return training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experienced-thread",
   "metadata": {},
   "outputs": [],
   "source": [
    "## isto naredi tudi z slikami za unet, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silent-commonwealth",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Eh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "international-notion",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_path = 'visual/'\n",
    "def initdir(filename):\n",
    "    path = vis_path + filename.replace(\".nii.gz\", \"/\")\n",
    "    if os.path.exists(path):\n",
    "        shutil.rmtree(path)\n",
    "    os.makedirs(path)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-thumbnail",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images_one(filename_img, train = True):\n",
    "    k_path = initdir(filename_img)\n",
    "    filename_mask = filename_img.replace(\".nii.gz\", \".nrrd\")\n",
    "    if train:\n",
    "        filepath_img = os.path.join(train_path, filename_img)\n",
    "        seg = segmentation_path +\"train/\"\n",
    "    else: \n",
    "        filepath_img = os.path.join(test_path, filename_img)\n",
    "        seg = segmentation_path +  \"test/\"\n",
    "    filepath_mask = os.path.join(seg, filename_mask)\n",
    "    patient_number = filename_mask.split(\".nrrd\")[0]\n",
    "    \n",
    "    img = mask_original(filepath_img, filepath_mask)\n",
    "    num_slices = img.shape[2]\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in tqdm(range(num_slices)):\n",
    "        store_path = k_path + str(i)+\"-\"\n",
    "        try:\n",
    "            current_slice, bbox_pixels = bound_box_and_reshape(img, i)\n",
    "        except:\n",
    "            continue\n",
    "        current_slice = np.rot90(np.squeeze(current_slice))\n",
    "        percentage = percent_lungs_slice(filepath_mask, i)\n",
    "        if percentage != 0:\n",
    "            # lahko v eni rundi kličem in semi in unet\n",
    "            plt.imsave(store_path+\"cur\"+\".png\", current_slice, cmap = 'gray')\n",
    "            current_slice = rgb_loader(store_path+\"cur\"+\".png\")\n",
    "            seg = transform(current_slice)\n",
    "            semi_mask = predict_net(seg)\n",
    "            plt.imsave(store_path+\"semi\"+\".png\", semi_mask, cmap = 'gray')\n",
    "            unet_mask = predict_unet(transform(rgb_loader(store_path+\"semi\"+\".png\")), seg)\n",
    "            plt.imsave(store_path+\"unet\"+\".png\", unet_mask, cmap = 'gray')\n",
    "            \n",
    "\n",
    "            ggo_mask, consolidation_mask = split_class_imgs(unet_mask)\n",
    "            plt.imsave(store_path+\"ggo\"+\".png\", ggo_mask, cmap = 'gray')\n",
    "            plt.imsave(store_path+\"conso\"+\".png\", consolidation_mask, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swedish-nightmare",
   "metadata": {},
   "outputs": [],
   "source": [
    "bet_path = '/media/pc/Elements/final/HACKATHON_finalround/images/train'\n",
    "seg_p = '/media/pc/Elements/final/HACKATHON_finalround/segmentations/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dependent-major",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "f = os.listdir(bet_path)[0]\n",
    "x = process_one_patient(f, bet_path, seg_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exempt-prize",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = process_all_patients(path = bet_path, seg_path = seg_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "velvet-yemen",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test = pd.DataFrame(y)\n",
    "final_test.to_csv('b.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consecutive-native",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kaggle(path, root = train_path):\n",
    "    store_path = ''\n",
    "    scan = nib.load(root+ path)\n",
    "    scan = np.array(scan.dataobj)\n",
    "    current_slice = np.rot90(scan[:,:,45], k=3)\n",
    "    plt.imsave(store_path+\"cur\"+\".jpg\", current_slice, cmap = 'gray')\n",
    "    current_slice = rgb_loader(store_path+\"cur\"+\".jpg\")\n",
    "    seg = transform(current_slice)\n",
    "    semi_mask = predict_semi(seg)\n",
    "    plt.imsave(store_path+\"semi\"+\".jpg\", semi_mask, cmap = 'gray')\n",
    "    unet_mask = predict_unet(transform(rgb_loader(store_path+\"semi\"+\".jpg\")), seg)\n",
    "    plt.imsave(store_path+\"unet\"+\".jpg\", unet_mask, cmap = 'gray')\n",
    "\n",
    "    ggo_mask, consolidation_mask = split_class_imgs(unet_mask)\n",
    "    return [ggo_mask, consolidation_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adequate-sustainability",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in os.listdir(kaggle_path):\n",
    "    a = []\n",
    "    a.append(kaggle(kaggle_path+k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "living-pacific",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finish some other time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenging-compiler",
   "metadata": {},
   "outputs": [],
   "source": [
    "def res2net50_v1b_26w_4s(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a Res2Net-50_v1b_26w_4s lib.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a lib pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = Res2Net(Bottle2neck, [3, 4, 6, 3], baseWidth=26, scale=4, **kwargs)\n",
    "    if pretrained:\n",
    "        model_state = torch.load('res2net50_v1b_26w_4s-3cf99910.pth',map_location=torch.device('cpu'))\n",
    "        model.load_state_dict(model_state)\n",
    "        # lib.load_state_dict(model_zoo.load_url(model_urls['res2net50_v1b_26w_4s']))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threaded-circus",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = train_path + '0000.nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tracked-crowd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_net(image):\n",
    "    es5, res4, res3, res2 = net(image)\n",
    "    res = res2\n",
    "    #res = F.upsample(res, size=(352,352), mode='bilinear', align_corners=False)\n",
    "    res = res.sigmoid().data.cpu().numpy().squeeze()\n",
    "    res = (res - res.min()) / (res.max() - res.min() + 1e-8)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rotary-paste",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joined-column",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = predict_net('cur.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "failing-albert",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frozen-frank",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_images_onenet('0434.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rental-garlic",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
